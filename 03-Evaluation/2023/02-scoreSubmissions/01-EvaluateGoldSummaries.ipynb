{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8aae8826",
   "metadata": {},
   "source": [
    "# Compare Wiki Summary and NIST Assessors\n",
    "\n",
    "This copies our assessment against whole-event summaries from CrisisFACTS 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6553dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06bdae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import gzip\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce70bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.12'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "\n",
    "import bert_score\n",
    "\n",
    "bert_score.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2337c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf795674",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = pd.read_json(\"CrisisFACTs-2022to2023.topics.withSummaries.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c8c6c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trecisID</th>\n",
       "      <th>dataset</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>wiki.summary</th>\n",
       "      <th>nist.summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-001</th>\n",
       "      <td>TRECIS-CTIT-H-092</td>\n",
       "      <td>2017_12_07_lilac_wildfire.2017</td>\n",
       "      <td>Lilac Wildfire 2017</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lilac_Fire</td>\n",
       "      <td>The Lilac Fire was a fire that burned in north...</td>\n",
       "      <td>The Lilac Fire was a fire that burned in north...</td>\n",
       "      <td>Wind gusts have been recorded at 40-50 mph in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-002</th>\n",
       "      <td>TRECIS-CTIT-H-095</td>\n",
       "      <td>2018_07_23_cranston_wildfire.2018</td>\n",
       "      <td>Cranston Wildfire 2018</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Cranston_Fire</td>\n",
       "      <td>The Cranston Fire was a wildfire that burned i...</td>\n",
       "      <td>The Cranston Fire was a wildfire that burned i...</td>\n",
       "      <td>An evacuation center had been set up at Bannin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-003</th>\n",
       "      <td>TRECIS-CTIT-H-097</td>\n",
       "      <td>2018_08_05_holy_wildfire.2018</td>\n",
       "      <td>Holy Wildfire 2018</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Holy_Fire_(2018)</td>\n",
       "      <td>The Holy Fire was a wildfire that burned in th...</td>\n",
       "      <td>The Holy Fire was a wildfire that burned in th...</td>\n",
       "      <td>The Holy Fire in California has forced the clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-004</th>\n",
       "      <td>TRECIS-CTIT-H-098</td>\n",
       "      <td>2018_09_07_hurricane_florence.2018</td>\n",
       "      <td>Hurricane Florence 2018</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hurricane_Florence</td>\n",
       "      <td>Hurricane Florence was a powerful and long-liv...</td>\n",
       "      <td>Hurricane Florence was a powerful and long-liv...</td>\n",
       "      <td>The hurricane has made landfall in the Carolin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-005</th>\n",
       "      <td>TRECIS-CTIT-H-101</td>\n",
       "      <td>2018_maryland_flood</td>\n",
       "      <td>2018 Maryland Flood</td>\n",
       "      <td>Flood</td>\n",
       "      <td>https://en.wikipedia.org/wiki/2018_Maryland_flood</td>\n",
       "      <td>In the afternoon of May 27, 2018, after over 8...</td>\n",
       "      <td>In the afternoon of May 27, 2018, after over 8...</td>\n",
       "      <td>Officials evacuated the area due to a gas leak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-006</th>\n",
       "      <td>TRECIS-CTIT-H-106</td>\n",
       "      <td>2019_10_10_saddleridge_wildfire.2019</td>\n",
       "      <td>Saddleridge Wildfire 2019</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Saddleridge_Fire</td>\n",
       "      <td>The Saddleridge Fire was a wildfire burning ne...</td>\n",
       "      <td>The Saddleridge Fire was a wildfire burning ne...</td>\n",
       "      <td>4,500 customers in Los Angeles and surrounding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-007</th>\n",
       "      <td>TRECIS-CTIT-H-113</td>\n",
       "      <td>2020_08_27_hurricane_laura.2020</td>\n",
       "      <td>Hurricane Laura 2020</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hurricane_Laura</td>\n",
       "      <td>Hurricane Laura was a deadly and destructive C...</td>\n",
       "      <td>Hurricane Laura was a deadly and destructive C...</td>\n",
       "      <td>Hurricane force winds amp catastrophic storm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-008</th>\n",
       "      <td>TRECIS-CTIT-H-114</td>\n",
       "      <td>2020_09_11_hurricane_sally.2020</td>\n",
       "      <td>Hurricane Sally 2020</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hurricane_Sally</td>\n",
       "      <td>Hurricane Sally was a destructive Atlantic hur...</td>\n",
       "      <td>Hurricane Sally was a destructive and slow-mov...</td>\n",
       "      <td>Railways have not closed. Tropical Storm Sally...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-009</th>\n",
       "      <td>TRECIS-CTIT-H-066</td>\n",
       "      <td>beirutExplosion2020</td>\n",
       "      <td>Beirut Explosion</td>\n",
       "      <td>Accident</td>\n",
       "      <td>https://en.wikipedia.org/wiki/2020_Beirut_expl...</td>\n",
       "      <td>On 4 August 2020, a large amount of ammonium n...</td>\n",
       "      <td>On 4 August 2020, a large amount of ammonium n...</td>\n",
       "      <td>The impact of the afternoon blast was felt in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-010</th>\n",
       "      <td>TRECIS-CTIT-H-076</td>\n",
       "      <td>2020_01_27_houston_explosion.2020</td>\n",
       "      <td>Houston Explosion 2020</td>\n",
       "      <td>Accident</td>\n",
       "      <td>https://en.wikipedia.org/wiki/2020_Houston_exp...</td>\n",
       "      <td>On January 24, 2020, a building at Watson Grin...</td>\n",
       "      <td>On January 24, 2020, a building at Watson Grin...</td>\n",
       "      <td>Massive fire rips through building near Housto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-011</th>\n",
       "      <td>TRECIS-CTIT-H-079</td>\n",
       "      <td>2020_02_07_rutherford_tn_floods.2020</td>\n",
       "      <td>Rutherford Floods 2020</td>\n",
       "      <td>Flood</td>\n",
       "      <td>https://www.dnj.com/story/weather/2020/02/13/r...</td>\n",
       "      <td>More than 40 Rutherford County roads were clos...</td>\n",
       "      <td></td>\n",
       "      <td>The National Weather Service has issued a * Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-012</th>\n",
       "      <td>TRECIS-CTIT-H-083</td>\n",
       "      <td>2020_05_06_tn_derecho.2020</td>\n",
       "      <td>Tennessee Derecho 2020</td>\n",
       "      <td>Storm</td>\n",
       "      <td>https://www.washingtonpost.com/weather/2020/05...</td>\n",
       "      <td>Residents in the Tennessee Valley are cleaning...</td>\n",
       "      <td></td>\n",
       "      <td>There are severe thunderstorm warnings current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-013</th>\n",
       "      <td>TRECIS-CTIT-H-084</td>\n",
       "      <td>2020_05_26_edenville_dam_failure.2020.corrected</td>\n",
       "      <td>Edenville Dam Failure 2020</td>\n",
       "      <td>Flood</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Edenville_Dam#Da...</td>\n",
       "      <td>On May 19, 2020, 5:46 p.m., due to massive inf...</td>\n",
       "      <td>Edenville Dam was an earthen embankment dam at...</td>\n",
       "      <td>Poseyville Road from Ashby Road to St. Charles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-014</th>\n",
       "      <td>TRECIS-CTIT-H-104</td>\n",
       "      <td>2019_08_25_hurricane_dorian.2019</td>\n",
       "      <td>Hurricane Dorian 2019</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Hurricane_Dorian</td>\n",
       "      <td>Hurricane Dorian was an extremely powerful and...</td>\n",
       "      <td>Hurricane Dorian was an extremely powerful and...</td>\n",
       "      <td>Actions to take: -evacuate if you are in an ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-015</th>\n",
       "      <td>TRECIS-CTIT-H-107</td>\n",
       "      <td>2019_10_25_kincade_wildfire.2019</td>\n",
       "      <td>Kincade Wildfire 2019</td>\n",
       "      <td>Wildfire</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kincade_Fire</td>\n",
       "      <td>The Kincade Fire was a wildfire that burned in...</td>\n",
       "      <td>The Kincade Fire was a wildfire that burned in...</td>\n",
       "      <td>Sonoma County Resilience Fund stands at the re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-016</th>\n",
       "      <td>TRECIS-CTIT-H-116</td>\n",
       "      <td>2020_easter_tornado_outbreak</td>\n",
       "      <td>2020 Easter Tornado Outbreak</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>https://en.wikipedia.org/wiki/2020_Easter_torn...</td>\n",
       "      <td>A widespread and deadly tornado outbreak affec...</td>\n",
       "      <td>A widespread and deadly tornado outbreak affec...</td>\n",
       "      <td>People in Kingston need to immediately take co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-017</th>\n",
       "      <td>TRECIS-CTIT-H-119</td>\n",
       "      <td>2020_tornado_outbreak_of_april</td>\n",
       "      <td>2020 Tornado Outbreak of April</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tornado_outbreak...</td>\n",
       "      <td>During the afternoon and evening of April 22, ...</td>\n",
       "      <td>On April 22, 2020, an outbreak of discrete sup...</td>\n",
       "      <td>#Tornado reported in Florida as severe weather...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrisisFACTS-018</th>\n",
       "      <td>TRECIS-CTIT-H-120</td>\n",
       "      <td>2020_tornado_outbreak_of_march</td>\n",
       "      <td>2020 Tornado Outbreak of March</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tornado_outbreak...</td>\n",
       "      <td>A small but deadly tornado outbreak affected W...</td>\n",
       "      <td>A small but deadly tornado outbreak affected W...</td>\n",
       "      <td>Hazardous chemicals and materials are involved...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          trecisID  \\\n",
       "CrisisFACTS-001  TRECIS-CTIT-H-092   \n",
       "CrisisFACTS-002  TRECIS-CTIT-H-095   \n",
       "CrisisFACTS-003  TRECIS-CTIT-H-097   \n",
       "CrisisFACTS-004  TRECIS-CTIT-H-098   \n",
       "CrisisFACTS-005  TRECIS-CTIT-H-101   \n",
       "CrisisFACTS-006  TRECIS-CTIT-H-106   \n",
       "CrisisFACTS-007  TRECIS-CTIT-H-113   \n",
       "CrisisFACTS-008  TRECIS-CTIT-H-114   \n",
       "CrisisFACTS-009  TRECIS-CTIT-H-066   \n",
       "CrisisFACTS-010  TRECIS-CTIT-H-076   \n",
       "CrisisFACTS-011  TRECIS-CTIT-H-079   \n",
       "CrisisFACTS-012  TRECIS-CTIT-H-083   \n",
       "CrisisFACTS-013  TRECIS-CTIT-H-084   \n",
       "CrisisFACTS-014  TRECIS-CTIT-H-104   \n",
       "CrisisFACTS-015  TRECIS-CTIT-H-107   \n",
       "CrisisFACTS-016  TRECIS-CTIT-H-116   \n",
       "CrisisFACTS-017  TRECIS-CTIT-H-119   \n",
       "CrisisFACTS-018  TRECIS-CTIT-H-120   \n",
       "\n",
       "                                                         dataset  \\\n",
       "CrisisFACTS-001                   2017_12_07_lilac_wildfire.2017   \n",
       "CrisisFACTS-002                2018_07_23_cranston_wildfire.2018   \n",
       "CrisisFACTS-003                    2018_08_05_holy_wildfire.2018   \n",
       "CrisisFACTS-004               2018_09_07_hurricane_florence.2018   \n",
       "CrisisFACTS-005                              2018_maryland_flood   \n",
       "CrisisFACTS-006             2019_10_10_saddleridge_wildfire.2019   \n",
       "CrisisFACTS-007                  2020_08_27_hurricane_laura.2020   \n",
       "CrisisFACTS-008                  2020_09_11_hurricane_sally.2020   \n",
       "CrisisFACTS-009                              beirutExplosion2020   \n",
       "CrisisFACTS-010                2020_01_27_houston_explosion.2020   \n",
       "CrisisFACTS-011             2020_02_07_rutherford_tn_floods.2020   \n",
       "CrisisFACTS-012                       2020_05_06_tn_derecho.2020   \n",
       "CrisisFACTS-013  2020_05_26_edenville_dam_failure.2020.corrected   \n",
       "CrisisFACTS-014                 2019_08_25_hurricane_dorian.2019   \n",
       "CrisisFACTS-015                 2019_10_25_kincade_wildfire.2019   \n",
       "CrisisFACTS-016                     2020_easter_tornado_outbreak   \n",
       "CrisisFACTS-017                   2020_tornado_outbreak_of_april   \n",
       "CrisisFACTS-018                   2020_tornado_outbreak_of_march   \n",
       "\n",
       "                                          title       type  \\\n",
       "CrisisFACTS-001             Lilac Wildfire 2017   Wildfire   \n",
       "CrisisFACTS-002          Cranston Wildfire 2018   Wildfire   \n",
       "CrisisFACTS-003              Holy Wildfire 2018   Wildfire   \n",
       "CrisisFACTS-004         Hurricane Florence 2018  Hurricane   \n",
       "CrisisFACTS-005             2018 Maryland Flood      Flood   \n",
       "CrisisFACTS-006       Saddleridge Wildfire 2019   Wildfire   \n",
       "CrisisFACTS-007            Hurricane Laura 2020  Hurricane   \n",
       "CrisisFACTS-008            Hurricane Sally 2020  Hurricane   \n",
       "CrisisFACTS-009                Beirut Explosion   Accident   \n",
       "CrisisFACTS-010          Houston Explosion 2020   Accident   \n",
       "CrisisFACTS-011          Rutherford Floods 2020      Flood   \n",
       "CrisisFACTS-012          Tennessee Derecho 2020      Storm   \n",
       "CrisisFACTS-013      Edenville Dam Failure 2020      Flood   \n",
       "CrisisFACTS-014           Hurricane Dorian 2019  Hurricane   \n",
       "CrisisFACTS-015           Kincade Wildfire 2019   Wildfire   \n",
       "CrisisFACTS-016    2020 Easter Tornado Outbreak    Tornado   \n",
       "CrisisFACTS-017  2020 Tornado Outbreak of April    Tornado   \n",
       "CrisisFACTS-018  2020 Tornado Outbreak of March    Tornado   \n",
       "\n",
       "                                                               url  \\\n",
       "CrisisFACTS-001           https://en.wikipedia.org/wiki/Lilac_Fire   \n",
       "CrisisFACTS-002        https://en.wikipedia.org/wiki/Cranston_Fire   \n",
       "CrisisFACTS-003     https://en.wikipedia.org/wiki/Holy_Fire_(2018)   \n",
       "CrisisFACTS-004   https://en.wikipedia.org/wiki/Hurricane_Florence   \n",
       "CrisisFACTS-005  https://en.wikipedia.org/wiki/2018_Maryland_flood   \n",
       "CrisisFACTS-006     https://en.wikipedia.org/wiki/Saddleridge_Fire   \n",
       "CrisisFACTS-007      https://en.wikipedia.org/wiki/Hurricane_Laura   \n",
       "CrisisFACTS-008      https://en.wikipedia.org/wiki/Hurricane_Sally   \n",
       "CrisisFACTS-009  https://en.wikipedia.org/wiki/2020_Beirut_expl...   \n",
       "CrisisFACTS-010  https://en.wikipedia.org/wiki/2020_Houston_exp...   \n",
       "CrisisFACTS-011  https://www.dnj.com/story/weather/2020/02/13/r...   \n",
       "CrisisFACTS-012  https://www.washingtonpost.com/weather/2020/05...   \n",
       "CrisisFACTS-013  https://en.wikipedia.org/wiki/Edenville_Dam#Da...   \n",
       "CrisisFACTS-014     https://en.wikipedia.org/wiki/Hurricane_Dorian   \n",
       "CrisisFACTS-015         https://en.wikipedia.org/wiki/Kincade_Fire   \n",
       "CrisisFACTS-016  https://en.wikipedia.org/wiki/2020_Easter_torn...   \n",
       "CrisisFACTS-017  https://en.wikipedia.org/wiki/Tornado_outbreak...   \n",
       "CrisisFACTS-018  https://en.wikipedia.org/wiki/Tornado_outbreak...   \n",
       "\n",
       "                                                       description  \\\n",
       "CrisisFACTS-001  The Lilac Fire was a fire that burned in north...   \n",
       "CrisisFACTS-002  The Cranston Fire was a wildfire that burned i...   \n",
       "CrisisFACTS-003  The Holy Fire was a wildfire that burned in th...   \n",
       "CrisisFACTS-004  Hurricane Florence was a powerful and long-liv...   \n",
       "CrisisFACTS-005  In the afternoon of May 27, 2018, after over 8...   \n",
       "CrisisFACTS-006  The Saddleridge Fire was a wildfire burning ne...   \n",
       "CrisisFACTS-007  Hurricane Laura was a deadly and destructive C...   \n",
       "CrisisFACTS-008  Hurricane Sally was a destructive Atlantic hur...   \n",
       "CrisisFACTS-009  On 4 August 2020, a large amount of ammonium n...   \n",
       "CrisisFACTS-010  On January 24, 2020, a building at Watson Grin...   \n",
       "CrisisFACTS-011  More than 40 Rutherford County roads were clos...   \n",
       "CrisisFACTS-012  Residents in the Tennessee Valley are cleaning...   \n",
       "CrisisFACTS-013  On May 19, 2020, 5:46 p.m., due to massive inf...   \n",
       "CrisisFACTS-014  Hurricane Dorian was an extremely powerful and...   \n",
       "CrisisFACTS-015  The Kincade Fire was a wildfire that burned in...   \n",
       "CrisisFACTS-016  A widespread and deadly tornado outbreak affec...   \n",
       "CrisisFACTS-017  During the afternoon and evening of April 22, ...   \n",
       "CrisisFACTS-018  A small but deadly tornado outbreak affected W...   \n",
       "\n",
       "                                                      wiki.summary  \\\n",
       "CrisisFACTS-001  The Lilac Fire was a fire that burned in north...   \n",
       "CrisisFACTS-002  The Cranston Fire was a wildfire that burned i...   \n",
       "CrisisFACTS-003  The Holy Fire was a wildfire that burned in th...   \n",
       "CrisisFACTS-004  Hurricane Florence was a powerful and long-liv...   \n",
       "CrisisFACTS-005  In the afternoon of May 27, 2018, after over 8...   \n",
       "CrisisFACTS-006  The Saddleridge Fire was a wildfire burning ne...   \n",
       "CrisisFACTS-007  Hurricane Laura was a deadly and destructive C...   \n",
       "CrisisFACTS-008  Hurricane Sally was a destructive and slow-mov...   \n",
       "CrisisFACTS-009  On 4 August 2020, a large amount of ammonium n...   \n",
       "CrisisFACTS-010  On January 24, 2020, a building at Watson Grin...   \n",
       "CrisisFACTS-011                                                      \n",
       "CrisisFACTS-012                                                      \n",
       "CrisisFACTS-013  Edenville Dam was an earthen embankment dam at...   \n",
       "CrisisFACTS-014  Hurricane Dorian was an extremely powerful and...   \n",
       "CrisisFACTS-015  The Kincade Fire was a wildfire that burned in...   \n",
       "CrisisFACTS-016  A widespread and deadly tornado outbreak affec...   \n",
       "CrisisFACTS-017  On April 22, 2020, an outbreak of discrete sup...   \n",
       "CrisisFACTS-018  A small but deadly tornado outbreak affected W...   \n",
       "\n",
       "                                                      nist.summary  \n",
       "CrisisFACTS-001  Wind gusts have been recorded at 40-50 mph in ...  \n",
       "CrisisFACTS-002  An evacuation center had been set up at Bannin...  \n",
       "CrisisFACTS-003  The Holy Fire in California has forced the clo...  \n",
       "CrisisFACTS-004  The hurricane has made landfall in the Carolin...  \n",
       "CrisisFACTS-005  Officials evacuated the area due to a gas leak...  \n",
       "CrisisFACTS-006  4,500 customers in Los Angeles and surrounding...  \n",
       "CrisisFACTS-007  Hurricane force winds amp catastrophic storm s...  \n",
       "CrisisFACTS-008  Railways have not closed. Tropical Storm Sally...  \n",
       "CrisisFACTS-009  The impact of the afternoon blast was felt in ...  \n",
       "CrisisFACTS-010  Massive fire rips through building near Housto...  \n",
       "CrisisFACTS-011  The National Weather Service has issued a * Fl...  \n",
       "CrisisFACTS-012  There are severe thunderstorm warnings current...  \n",
       "CrisisFACTS-013  Poseyville Road from Ashby Road to St. Charles...  \n",
       "CrisisFACTS-014  Actions to take: -evacuate if you are in an ar...  \n",
       "CrisisFACTS-015  Sonoma County Resilience Fund stands at the re...  \n",
       "CrisisFACTS-016  People in Kingston need to immediately take co...  \n",
       "CrisisFACTS-017  #Tornado reported in Florida as severe weather...  \n",
       "CrisisFACTS-018  Hazardous chemicals and materials are involved...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb5f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c17122ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"wiki.summary\", \"nist.summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4bc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d83e4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = ROUGEScore(\n",
    "    use_stemmer=True,\n",
    "    rouge_keys=(\"rouge2\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df09f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6aec7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wiki.summary', 'nist.summary'), ('nist.summary', 'wiki.summary')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pairs = []\n",
    "for t1 in targets:\n",
    "    for t2 in targets:\n",
    "        if t1 == t2:\n",
    "            continue\n",
    "        target_pairs.append((t1, t2))\n",
    "        \n",
    "target_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cac23d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-001\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-002\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-003\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-004\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-005\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-006\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-007\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-008\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-009\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-010\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-011\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-012\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-013\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-014\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-015\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-016\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-017\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-018\n",
      "\t wiki.summary nist.summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-xlarge-mnli were not used when initializing DebertaModel: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:679: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  query_layer = query_layer / torch.tensor(scale, dtype=query_layer.dtype)\n",
      "/Users/cbuntain/.local/lib/python3.9/site-packages/transformers/models/deberta/modeling_deberta.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  p2c_att = torch.matmul(key_layer, torch.tensor(pos_query_layer.transpose(-1, -2), dtype=key_layer.dtype))\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for event_id,row in summaries.iterrows():\n",
    "    print(event_id)\n",
    "\n",
    "\n",
    "    for t1,t2 in target_pairs[:1]:\n",
    "        print(\"\\t\", t1, t2)\n",
    "            \n",
    "        metric = rouge(row[t1], row[t2])\n",
    "        bert_metric = bert_score.score(\n",
    "            [row[t1]], \n",
    "            [row[t2]], \n",
    "            model_type=\"microsoft/deberta-xlarge-mnli\"\n",
    "        )\n",
    "        \n",
    "        metric.update({\n",
    "            \"bertscore_precision\": bert_metric[0],\n",
    "            \"bertscore_recall\": bert_metric[1],\n",
    "            \"bertscore_fmeasure\": bert_metric[2],\n",
    "        })\n",
    "        \n",
    "\n",
    "        this_metric_rows = [{\n",
    "            \"metric\":k, \n",
    "            \"value\":v.item(), \n",
    "            \"event\": event_id,\n",
    "            \"target\": \"%s->%s\" % (t1,t2)\n",
    "        } for k,v in metric.items()]\n",
    "        this_row_df = pd.DataFrame(this_metric_rows)\n",
    "        rows.append(this_row_df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2ea6b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>event</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rouge2_fmeasure</td>\n",
       "      <td>0.024010</td>\n",
       "      <td>CrisisFACTS-001</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2_precision</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>CrisisFACTS-001</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge2_recall</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>CrisisFACTS-001</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertscore_precision</td>\n",
       "      <td>0.590926</td>\n",
       "      <td>CrisisFACTS-001</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bertscore_recall</td>\n",
       "      <td>0.520302</td>\n",
       "      <td>CrisisFACTS-001</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rouge2_precision</td>\n",
       "      <td>0.320611</td>\n",
       "      <td>CrisisFACTS-018</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rouge2_recall</td>\n",
       "      <td>0.010742</td>\n",
       "      <td>CrisisFACTS-018</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertscore_precision</td>\n",
       "      <td>0.585559</td>\n",
       "      <td>CrisisFACTS-018</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bertscore_recall</td>\n",
       "      <td>0.498592</td>\n",
       "      <td>CrisisFACTS-018</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bertscore_fmeasure</td>\n",
       "      <td>0.538587</td>\n",
       "      <td>CrisisFACTS-018</td>\n",
       "      <td>wiki.summary-&gt;nist.summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 metric     value            event                      target\n",
       "0       rouge2_fmeasure  0.024010  CrisisFACTS-001  wiki.summary->nist.summary\n",
       "1      rouge2_precision  0.277778  CrisisFACTS-001  wiki.summary->nist.summary\n",
       "2         rouge2_recall  0.012547  CrisisFACTS-001  wiki.summary->nist.summary\n",
       "3   bertscore_precision  0.590926  CrisisFACTS-001  wiki.summary->nist.summary\n",
       "4      bertscore_recall  0.520302  CrisisFACTS-001  wiki.summary->nist.summary\n",
       "..                  ...       ...              ...                         ...\n",
       "1      rouge2_precision  0.320611  CrisisFACTS-018  wiki.summary->nist.summary\n",
       "2         rouge2_recall  0.010742  CrisisFACTS-018  wiki.summary->nist.summary\n",
       "3   bertscore_precision  0.585559  CrisisFACTS-018  wiki.summary->nist.summary\n",
       "4      bertscore_recall  0.498592  CrisisFACTS-018  wiki.summary->nist.summary\n",
       "5    bertscore_fmeasure  0.538587  CrisisFACTS-018  wiki.summary->nist.summary\n",
       "\n",
       "[108 rows x 4 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.concat(rows)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26262f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8bace848",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = all_df.pivot(\"event\", \"metric\", \"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3bfb7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = metric_df[~metric_df.index.isin([\"CrisisFACTS-011\", \"CrisisFACTS-012\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2ec30f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='bertscore_fmeasure', ylabel='rouge2_fmeasure'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_df[[\"bertscore_fmeasure\", \"rouge2_fmeasure\"]].plot.scatter(x=\"bertscore_fmeasure\", y=\"rouge2_fmeasure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7c5c0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>metric</th>\n",
       "      <th>bertscore_fmeasure</th>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bertscore_fmeasure</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.12324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rouge2_fmeasure</th>\n",
       "      <td>0.12324</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric              bertscore_fmeasure  rouge2_fmeasure\n",
       "metric                                                 \n",
       "bertscore_fmeasure             1.00000          0.12324\n",
       "rouge2_fmeasure                0.12324          1.00000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df[[\"bertscore_fmeasure\", \"rouge2_fmeasure\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "00a588c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "metric & bertscore_fmeasure & rouge2_fmeasure \\\\\n",
      "metric &  &  \\\\\n",
      "bertscore_fmeasure & 1.000000 & 0.123240 \\\\\n",
      "rouge2_fmeasure & 0.123240 & 1.000000 \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metric_df[[\"bertscore_fmeasure\", \"rouge2_fmeasure\"]].corr().style.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35b3d0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metric\n",
       "bertscore_fmeasure    0.553641\n",
       "rouge2_fmeasure       0.039266\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df[[\"bertscore_fmeasure\", \"rouge2_fmeasure\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b710b538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
